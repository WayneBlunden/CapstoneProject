# Code:You 
####  Data Analysis Capstone Project
This project intends to analyze traffic accidents throughout the US between 2016 and 2023. It will also look at the affect of marijauna legalization on accidents in those states where it has been made legal in some form. Utilizing the various python scripts in this repository we will acquire our raw data to feed into the cleaning program, clean the data for final review, and finally use the cleaned data to answer several questions and provide visualizations of that data.

### Tools Used

GitBash/Terminal
??Database tool??
This project was conducted using python, focusing on the Pandas library, to generate and clean the data for analysis. Tableau was used for final visualizations. 
Other libraries used throughout the project
 - SQLite
 - OS
 - Wikipedia

## Start Here

### 1. Create a virtual Environment
| Step | Description | Code | 
| ---- | ----------- | ---- | 
| 1    | Navigate to the desired folder in gitbash/terminal. Clone the Repo to your machine   |     |
|2     | Create a virtual environment in the project folder. | python3 -m venv venv |
|3     | Activate the virtual environment |  |
|  | Windows: | source venv/Scripts/activate |
|  | Other: | source venv/bin/activate |
| 4    | Install the required packages | pip install -r requirements.txt |
| 5    | When you are done working deactivate the environment | deactivate |

### 2. Needed Datafiles and File Management.
You will need two datafiles to start with  
> **Legalization.csv** will be generated by running 'LegalizationDataPull.py';  included in this repository  
> **US_Accidents_March23.csv** can be downloaded from [kaggle.com](https://www.kaggle.com/datasets/sobhanmoosavi/us-accidents). Download the zip file and ensure it is saved in the /Data/Raw directory created when generating 'Legalization.csv'

### 3. Data Discovery
Jupyter notebook was utilized to complete the data discovery of US_Accidents_March23.csv.  
> Due to the size of the dataset the Discovery.ipynb file was too large to upload to GitHub. If you would like to view it, it can be downloaded from (google drive location?)

### 4. Cleaning Phase
You will run the python script labeled **Cleaning.py**  
 > This will run through the tasks listed below to generate a final clean data set to use with our visualaztions and analysis  

### 4. Analysis ?????

### 5. Visualization

### 6. ?Profit?